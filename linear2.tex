\part{Systems of linear equations I - Direct methods}
\section{Introduction}
\subsection*{General}
\begin{frame}[label=contents_lin2]
  \frametitle{Today's outline}
  \mode<beamer>{
    \only<1>{\tableofcontents}
  }
  \only<2>{\tableofcontents[currentsection,currentsubsection]}
\end{frame}

\begin{frame}
  \frametitle{Overview}
  \begin{block}{Goals}
    Today we are going to write a program, which can solve a set of linear equations
    \begin{itemize}
      \item The first method is called Gaussian elimination
      \item We will encounter some problems with Gaussian elimination
      \item Then LU decomposition will be introduced
  \end{itemize}
  \end{block}
\end{frame}

\section{Gauss elimination}
\subsection*{Row operations}
\againframe<2>{contents_lin2}
\frame{
  \frametitle{Define the linear system}
   Consider the system: 
   \[
      Ax = b
   \]
   \vfill
   In general:
    \[ 
    \begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
A_{10} & A_{11} & A_{12}\\ 
A_{20} & A_{21} & A_{22}
\end{bmatrix}\begin{bmatrix}
x_0\\x_1\\x_2  
\end{bmatrix}=\begin{bmatrix}b_0\\b_1\\b_2  \end{bmatrix} 
\]
  \vfill
Desired solution:
    \[ 
    \begin{bmatrix}
1 & 0 & 0\\ 
0 & 1 & 0\\ 
0 & 0 & 1
\end{bmatrix}\begin{bmatrix}
x_0\\x_1\\x_2  
\end{bmatrix}=\begin{bmatrix}b'_0\\b'_1\\b'_2\end{bmatrix} 
\]
}

\begin{frame}[fragile]
  \frametitle{Using row operations}
  \begin{itemize}
    \item Use row operations to simplify the system. Eliminate element $A_{10}$ by subtracting $A_{10}/A_{00} = d_{10}$ times row 1 from row 2.
    \item In this case, Row 1 is the pivot row, and $A_{00}$ is the pivot element.
  \end{itemize}
  \tikz{\node (m1) {
    $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      \tikzmarkin[txt=style yellow]{a21a} A_{10} & A_{11} & A_{12} & b_1\tikzmarkend{a21a}\\ 
      A_{20} & A_{21} & A_{22} & b_2
    \end{array}\right]
  $};
  \node[right=2cm of m1,](m2){
  $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      \tikzmarkin[txt=style yellow] {a21b} 0      & A'_{11} & A'_{12} & b'_1\tikzmarkend{a21b}\\ 
      A_{20} & A_{21} & A_{22} & b_2
    \end{array}\right]
  $};
  \draw[->,thick] (m1.east) --  (m2.west);
  }
\end{frame}

\begin{frame}[fragile]
  \frametitle{Using row operations}
  Eliminate element $A_{10}$ using $d_{10}=A_{10}/A_{00}$.
  \vfill
    \tikz{\node (m1) {
    $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      \tikzmarkin[txt=style yellow] {a211}A_{10} & A_{11} & A_{12} & b_1\tikzmarkend{a211}\\ 
      A_{20} & A_{21} & A_{22} & b_2
    \end{array}\right]
  $};
  \node[right=2cm of m1,](m2){
  $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      \tikzmarkin[txt=style yellow] {a212} 0      & A'_{11} & A'_{12} & b'_1\tikzmarkend{a212}\\ 
      A_{20} & A_{21} & A_{22} & b_2
    \end{array}\right]
  $};
  \draw[->,thick] (m1.east) --  (m2.west);
  }
  \vfill\pause
  \begin{columns}
  \column{0.4\textwidth}
  \begin{itemize}
    \item $d_{10}\rightarrow A_{10}/A_{00}$
    \item $A_{10}\rightarrow A_{10}-A_{00}d_{10}$
    \item $A_{11}\rightarrow A_{11}-A_{01}d_{10}$
    \item $A_{12}\rightarrow A_{12}-A_{02}d_{10}$
    \item $b_1   \rightarrow b_1   -b_0   d_{10}$
  \end{itemize}
  \pause
  \column{0.6\textwidth}
   \begin{lstlisting}
d10 = A[1,0]/A[0,0]
A[1,0] -= A[0,0]*d10
A[1,1] -= A[0,1]*d10
A[1,2] -= A[0,2]*d10
b[1] -= b[0]*d10
   \end{lstlisting}
  \end{columns}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Using row operations}
  Eliminate element $A_{20}$ using $d_{20}=A_{20}/A_{00}$.
  \vfill
    \tikz{\node (m1) {
    $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      0 & A'_{11} & A'_{12} & b'_1\\ 
      \tikzmarkin[txt=style yellow] {a311}A_{20} & A_{21} & A_{22} & b_2\tikzmarkend{a311}
    \end{array}\right]
  $};
  \node[right=2cm of m1,](m2){
  $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      0      & A'_{11} & A'_{12} & b'_1\\ 
      \tikzmarkin[txt=style yellow] {a312}0 & A'_{21} & A'_{22} & b'_2\tikzmarkend{a312}
    \end{array}\right]
  $};
  \draw[->,thick] (m1.east) --  (m2.west);
  }
  \vfill\pause
  \begin{columns}
  \column{0.4\textwidth}
  \begin{itemize}
    \item $d_{20}\rightarrow A_{20}/A_{00}$
    \item $A_{20}\rightarrow A_{20}-A_{00}d_{20}$
    \item $A_{21}\rightarrow A_{21}-A_{01}d_{20}$
    \item $A_{22}\rightarrow A_{22}-A_{02}d_{20}$
    \item $b_2   \rightarrow b_2   -b_0   d_{20}$
  \end{itemize}
  \column{0.6\textwidth}
  \begin{lstlisting}
d20 = A[2,0]/A[0,0]
A[2,0] -= A[0,0]*d20
A[2,1] -= A[0,1]*d20
A[2,2] -= A[0,2]*d20
b[2] -= b[0]*d20
  \end{lstlisting}
  \end{columns}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Using row operations}
  Eliminate element $A'_{21}$ using $d_{21}=A'_{21}/A'_{11}$. Note that now the second row has become the pivot row.
  \vfill
    \tikz{\node (m1) {
    $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      0 & A'_{11} & A'_{12} & b'_1\\ 
      \tikzmarkin[txt=style yellow] {a311b} 0 & A'_{21} & A'_{22} & b'_2\tikzmarkend{a311b}
    \end{array}\right]
  $};
  \node[right=2cm of m1,](m2){
  $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      0      & A'_{11} & A'_{12} & b'_1\\ 
      \tikzmarkin[txt=style yellow] {a312b}0 & 0 & A''_{22} & b''_2\tikzmarkend{a312b}
    \end{array}\right]
  $};
  \draw[->,thick] (m1.east) --  (m2.west);
  }
  \vfill\pause
  \begin{columns}
  \column{0.4\textwidth}
  \begin{itemize}
    \item $d_{21}\rightarrow A_{21}/A'_{11}$
    \item $A_{21}\rightarrow A_{21}-A'_{11}d_{21}$
    \item $A_{22}\rightarrow A_{22}-A'_{12}d_{21}$
    \item $b_2   \rightarrow b_2   -b'_2   d_{21}$
  \end{itemize}
  \column{0.6\textwidth}
   \begin{lstlisting}
d21 = A[2,1]/A[1,1]
A[2,1] -= A[1,1]*d21
A[2,2] -= A[1,2]*d21
b[2] -= b[1]*d21
   \end{lstlisting}
  \end{columns}
  \pause
  \vfill
  The matrix is now a triangular matrix --- the solution can be obtained by back-substitution.
\end{frame}

\subsection*{Backsubstitution}
\begin{frame}[fragile]
  \frametitle{Backsubstitution}
  The system now reads:
  \[
    \begin{bmatrix}
      A_{00} & A_{01} & A_{02}\\ 
      0      & A'_{11} & A'_{12}\\ 
      0 & 0 & A''_{22}
    \end{bmatrix}
    \begin{bmatrix}x_0\\x_1\\x_2\end{bmatrix} = 
    \begin{bmatrix}b_0\\b'_1\\b''_2\end{bmatrix}
  \]
  \pause
  Start at the last row $N$, and work upward until row 1.
  \begin{columns}
  \column{0.4\textwidth}
    \begin{align*}
     x_2 &= b''_2/A''_{22}\\
     x_1 &= (b'_1 - A'_{12}x_2)/A'_{11}\\
     x_0 &= (b_0 - A_{01}x_1 - A_{02}x_2)/A_{00}
    \end{align*}
    \pause
  \column{0.6\textwidth}
    \begin{lstlisting}
x = np.empty([3,1])
x[2] = b[2]/A[2,2]
x[1] = (b[1] - A[1,2]*x[2])/A[1,1]
x[0] = (b[0] - A[0,1]*x[1] - A[0,2]*x[2])/A[0,0]
    \end{lstlisting}
\end{columns}
In general:
\[
 x_N = \frac{b_N}{A_{NN}} \qquad x_i = \frac{b_i - \sum_{j=i+1}^{N}A_{ij}x_j}{A_{ii}}
\]
\end{frame}

\begin{frame}[fragile]
  \frametitle{Writing the program}
  \begin{itemize}
   \item Create a function that takes matrix $A$ and right-hand side vector $b$ as input, and reduces the matrix and right-hand side to \emph{echelon form}. Additionally, create a function to perform the back-substitution:
  \begin{lstlisting}
def gaussian_elimination(A,b):
    # ... implementation /...
    return A,b

def backsubstitution(A,b):
    # ... implementation /...
    return x
  \end{lstlisting}
  \item We will use \emph{for-loops} instead of typing out each command line.
  \item Recall array slicing operations:
  \begin{itemize}
  \item \lstinline$A[0,:]$   = $[A_{00}, A_{01}, A_{02}]$
  \item \lstinline$A[:,1]}$   = $[A_{01}, A_{11}, A_{21}]^T$
  \item \lstinline$A[0,1:]$ = $[A_{01}, A_{02}]$
  \end{itemize}
  \item A row operation could look like:
  \begin{lstlisting}
A[i,:] = A[i,:] - d*A[1,:]
  \end{lstlisting}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{The program: elimination}
  \begin{lstlisting}
def gaussian_elimination(A,b):
    rows,cols = np.shape(A)
    for col in range(cols):
        for row in range(col+1,rows):
            d = A[row,col] / A[col,col]
            A[row,:] = A[row,:] - d*A[col,:]
            b[row]= b[row]-d*b[col]
    return A,b
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
  \frametitle{The program: Backsubstitution}
  \begin{lstlisting}
def backsubstitution(A,b):
    rows,cols = np.shape(A)
    x = np.zeros_like(b)

    for row in reversed(range(rows)):
        x[row] = b[row]
        for i in range(row+1,rows):
            x[row] = x[row]-A[row,i]*x[i]
        x[row]=x[row]/A[row,row]
    return x
  \end{lstlisting}
  \[
     x_N = \frac{b_N}{A_{NN}} \qquad x_i = \frac{b_i - \sum_{j=i+1}^{N}A_{ij}x_j}{A_{ii}}
  \]
\end{frame}

\begin{frame}[fragile]{Provide a convenient wrapper function}
    \begin{lstlisting}
def solve_ge(A,b):
    """
    Solve linear system Ax=b using Gaussian Elimination and backsubstitution

    Arguments: square coefficient matrix A, right-hand side vector b
    Note that A and b are modified in-place.
    """
    A,b = gaussian_elimination(A,b)
    x = backsubstitution(A,b)
    return x,A,b

A = np.array([[1.,1.,1.],[2.,1.,3.],[3.,1.,6.]])
b = np.array([[4.,7.,5.]]).T

x = solve_ge(A,b)
print(f'Solution found:\n{x}')
    \end{lstlisting}
    \begin{lstlisting}[style=output]
Solution found:
[[13.]
[-4.]
[-5.]]
     \end{lstlisting}  
\end{frame}

\begin{frame}[fragile]
  \frametitle{Exercise: Gaussian Elimination}
  \begin{itemize}
    \item The function we just made can be found on Canvas
    \item Import the \lstinline$solve_ge$ function in a separate script
    \item Solve the following system of equations:
    \[
    \begin{bmatrix}
      9 & 9 & 5 & 2\\ 
      6 & 7 & 1 & 3\\ 
      6 & 4 & 3 & 5\\
      2 & 6 & 2 & 1
    \end{bmatrix}
    \begin{bmatrix}x_0\\x_1\\x_2\\x_4\end{bmatrix} = 
    \begin{bmatrix}7\\4\\10\\1\end{bmatrix}
  \]
  \item Compare your solution with \lstinline$npla.solve(A,b)$
  \end{itemize}
\end{frame}

\begin{frame}<handout:0|beamer:1->[fragile]
  \frametitle{Exercise: performance of inverse computation}
  \begin{columns}
    \column{0.7\textwidth}
    \begin{lstlisting}
import numpy as np
from gaussian_elimination import solve_ge

A = np.array([[9,9,5,2],[6,7,1,3],[6,4,3,5],[2,6,2,1]],dtype=np.float64)
b = np.array([[7,4,10,1]],dtype=np.float64).T

print(f'Default solver:\n {np.linalg.solve(A,b)}')
print(f'Gauss Elimination solver:\n {solve_ge(A,b)}')
  \end{lstlisting}
      
    \column{0.3\textwidth}
      \begin{lstlisting}[style=output]
Default solver:
[[ 0.49322493]
[-0.52574526]
[ 0.95663957]
[ 1.25474255]]
Gauss Elimination solver:
[[ 0.49322493]
[-0.52574526]
[ 0.95663957]
[ 1.25474255]]
      \end{lstlisting}
  \end{columns}
  \pause
  Note the importance of the type:
  \begin{columns}
    \column{0.7\textwidth}
    \begin{lstlisting}
import numpy as np
from gaussian_elimination import solve_ge

A = np.array([[9,9,5,2],[6,7,1,3],[6,4,3,5],[2,6,2,1]])
b = np.array([[7,4,10,1]]).T

print(f'Gauss Elimination solver:\n {solve_ge(A,b)}')
      \end{lstlisting}
      
    \column{0.3\textwidth}
      \begin{lstlisting}[style=output]
Gauss Elimination solver:
[[ 1]
[-1]
[ 0]
[ 1]]
      \end{lstlisting}
  \end{columns}
  
\end{frame}

\section{Partial Pivoting}
\subsection*{Pivoting}
\againframe<2>{contents_lin2}

\begin{frame}[fragile]
  \frametitle{Partial pivoting}
  \begin{itemize}
    \item Now try to run the algorithm with the following system:
    \[
    \begin{bmatrix}
      0 & 2 & 1\\ 
      3 & 2 & 1 \\ 
      1 & 1 & 1
    \end{bmatrix}
    \begin{bmatrix}x_0\\x_1\\x_2\end{bmatrix} = 
    \begin{bmatrix}4\\3\\10\end{bmatrix}
  \]
  \pause
  \item It does not work! Division by zero, due to $A_{00}=0$.
  \item Solution: Swap rows to move largest element to the diagonal.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Partial pivoting: implementing row swaps}
  \begin{itemize}
    \item<1-> \tikzmarkin[txt=style yellow]{tm1} Find maximum element row below pivot in current column\tikzmarkend{tm1}
    \item<2-> \tikzmarkin[txt=style orange]{tm3}Swap pivot row and desired row in A\tikzmarkend{tm3}
    \item<3-> \tikzmarkin[txt=style cyan]{tm4}Do the same for b: store and swap\tikzmarkend{tm4}
  \end{itemize}
\lstinputlisting[backgroundcolor=\color{tueyellow!60}]{data/listing1.m}
\uncover<2->{\lstinputlisting[backgroundcolor=\color{tueorange!60}]{data/listing3.m}}
\uncover<3->{\lstinputlisting[backgroundcolor=\color{tuelblue!60}]{data/listing4.m}}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Improve the program by using re-usable functions}
  \begin{lstlisting}
def gaussian_elimination_pivot_solve(A,b):
    rows,cols = np.shape(A)
    for col in range(cols):
        imax = np.argmax(A[col:,col])
        imax += col
        A[[col,imax],:] = A[[imax,col],:]
        b[[col,imax],:] = b[[imax,col]]
        for row in range(col+1,rows):
            d = A[row,col] / A[col,col]
            A[row,:] = A[row,:] - d*A[col,:]
            b[row]= b[row]-d*b[col]
    
    x = backsubstitution(A,b)
    return x 
  \end{lstlisting}
  This function is also provided in the \lstinline$gaussian_elimination.py$ library file.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Alternatives to this program}
  \begin{itemize}
    \item Normally you would compute the solution to $Ax=b$ with specialized solvers (more efficient) from the NumPy or SciPy libraries.
    \item Too many loops. Loops make programs slow.
    \item There are fundamental problems with Gaussian elimination\pause
    \begin{itemize}
      \item You can add a counter to the algorithm to see how many subtraction and multiplication operations it performs for a given size of matrix A.
      \item The number of operations to perform Gaussian elimination is $\mathcal{O}(2N^3)$ (where $N$ is the number of equations) 
      \item Exercise: verify this for our script \pause
      \item LU decomposition takes $\mathcal{O}(2N^3/3)$ flops, 3 times less!
      \item Forward and backward substitution each take $\mathcal{O}(N^2)$
flops (both cases) 
    \end{itemize}
  \end{itemize}
\end{frame}

\section{LU decomposition}
\subsection*{LU}
\againframe<2>{contents_lin2}

\begin{frame}[fragile]
  \frametitle{LU Decomposition}
  Suppose we want to solve the previous set of equations, but with several right hand sides:
    \[ 
    \begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
A_{10} & A_{11} & A_{12}\\ 
A_{20} & A_{21} & A_{22}
\end{bmatrix}
\begin{bmatrix}
\vdots & \vdots & \vdots \\
x_0 & x_1 & x_2 \\
\vdots & \vdots & \vdots
\end{bmatrix} = 
\begin{bmatrix}
\vdots & \vdots & \vdots \\
b_0 & b_1 & b_2 \\
\vdots & \vdots & \vdots
\end{bmatrix}
\]\pause
Factor the matrix A into two matrices, L and U, such that $A=LU$:
\[ 
    \begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
A_{10} & A_{11} & A_{12}\\ 
A_{20} & A_{21} & A_{22}
\end{bmatrix} = 
\begin{bmatrix}
1 & 0 & 0 \\
\times & 1 & 0 \\
\times & \times & 1
\end{bmatrix}
\begin{bmatrix}
\times & \times & \times \\
0 & \times & \times \\
0 & 0 & \times
\end{bmatrix}
\]
Now we can solve for each right hand side, using only a forward
followed by a backward substitution!
\end{frame}

\begin{frame}[fragile]
  \frametitle{Substitutions}
  \begin{itemize}
    \item Define a lower and upper matrix $L$ and $U$ so that $A = LU$
    \item Therefore $LUx = b$
    \item Define a new vector $y = Ux$ so that $Ly = b$
    \item Solve for $y$, use $L$ and forward substitution
    \item Then we have $y$, solve for $x$, use $Ux = y$
    \item Solve for $x$, use $U$ and backward substitution
    \item But how to get L and U?
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Decomposing the matrix (1)}
  When we eliminate the element $A_{10}$ we can keep multiplying by a matrix that undoes this row operations, so that the product remains equal to $A$.
\[ 
\begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
A_{10} & A_{11} & A_{12}\\ 
A_{20} & A_{21} & A_{22}
\end{bmatrix} = 
\begin{bmatrix}
1 & 0 & 0 \\
d_{10}& 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
\begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
0 & A_{11}-d_{10}A_{01} & A_{12}-d_{10}A_{02}\\ 
A_{20} & A_{21} & A_{22}
\end{bmatrix}
\]
\end{frame}

\begin{frame}[fragile]
  \frametitle{Decomposing the matrix (2)}
  When we eliminate the element $A_{20}$ we can keep multiplying by a matrix that undoes this row operations, so that the product remains equal to $A$.
\[ 
A = 
\begin{bmatrix}
1 & 0 & 0 \\
d_{10}& 1 & 0 \\
d_{20} & 0 & 1
\end{bmatrix}
\begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
0 & A'_{11}=A_{11}-d_{10}A_{01} & A'_{12} = A_{12}-d_{10}A_{02}\\ 
0 & A'_{21} = A_{21}-d_{20}A_{01} & A'_{22} = A_{22}-d_{20}A_{10}
\end{bmatrix}
\]
\end{frame}

\begin{frame}[fragile]
  \frametitle{Decomposing the matrix (3)}
  When we eliminate the element $A_{21}$ we can keep multiplying by a matrix that undoes this row operations, so that the product remains equal to $A$.
\[ 
\begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
A_{10} & A_{11} & A_{12}\\ 
A_{20} & A_{21} & A_{22}
\end{bmatrix} = 
\begin{bmatrix}
1 & 0 & 0 \\
d_{10}& 1 & 0 \\
d_{20} & d_{21} & 1
\end{bmatrix}
\begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
0 & A'_{11} & A'_{12} \\ 
0 & 0  & A''_{22} = A'_{22}-d_{21}A'_{12}
\end{bmatrix}
\]\pause
We now have a lower matrix $L$ and an upper matrix $U$. This finishes the LU decomposition! 
\end{frame}

\subsection*{Pivoting in LU decomposition}
{\nologo
\begin{frame}[fragile]
\frametitle{Pivoting during decomposition}
Suppose we have arrived at the situation below, where $A'_{21}>A'_{11}$:
\vfill
\[ 
\begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
A_{10} & A_{11} & A_{12}\\ 
A_{20} & A_{21} & A_{22}
\end{bmatrix} = 
\begin{bmatrix}
1 & 0 & 0 \\
d_{10}& 1 & 0 \\
d_{20} & 0 & 1
\end{bmatrix}
\begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
0 & \tikzmarkin[mat=style green]{n1} A'_{11} & A'_{12} \\ 
0 & A'_{21}\tikzmarkend{n1} & A'_{22} 
\end{bmatrix}
\]
\vfill 
\pause
Exchange rows 2 and 3 to get the largest value on the main diagonal. Use a permutation matrix to store the swapped rows:
\vfill
\pause
\[ 
\begin{bmatrix}
\tikzmarkin[txt=style green]{n2} 1 & 0 & 0 \\
0& 0 & 1 \\
0 & 1 & 0 \tikzmarkend{n2}
\end{bmatrix}
\begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
A_{10} & A_{11} & A_{12}\\ 
A_{20} & A_{21} & A_{22}
\end{bmatrix} = 
\begin{bmatrix}
1 & 0 & 0 \\
\tikzmarkin[txt=style orange]{n3} d_{20}& 0 & 1 \tikzmarkend{n3}\\
\tikzmarkin[txt=style orange]{n4} d_{10} & 1 & 0 \tikzmarkend{n4}
\end{bmatrix}
\begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
\tikzmarkin[txt=style orange]{n5}0 & A'_{21} & A'_{22} \tikzmarkend{n5}\\ 
\tikzmarkin[txt=style orange]{n6}0 & A'_{11} & A'_{12} \tikzmarkend{n6} 
\end{bmatrix}
\]
\pause
Multiplying with a permutation matrix will swap the rows of a matrix. The permutation matrix is just an identity matrix, whose rows
have been interchanged.
\end{frame}
}
% 
% \begin{frame}[fragile]
% \frametitle{Pivoting during decomposition}
% Multiplying with a permutation matrix will swap the rows of a matrix. The permutation matrix is just an identity matrix, whose rows
% have been interchanged.
% \vfill
% \[ 
% \begin{bmatrix}
% 1 & 0 & 0 \\
% 0& 0 & 1 \\
% 0 & 1 & 0
% \end{bmatrix}
% \begin{bmatrix}
% A_{00} & A_{01} & A_{02}\\ 
% A_{10} & A_{11} & A_{12}\\ 
% A_{20} & A_{21} & A_{22}
% \end{bmatrix} = 
% \begin{bmatrix}
% 1 & 0 & 0 \\
% d_{20}& 0 & 1 \\
% d_{10} & 1 & 0
% \end{bmatrix}
% \begin{bmatrix}
% A_{00} & A_{01} & A_{02}\\ 
% 0 & A'_{32} & A'_{33} \\ 
% 0 & A'_{11} & A'_{12} 
% \end{bmatrix}
% \]
% \end{frame}

\begin{frame}[fragile]
  \frametitle{Recipe for LU decomposition}
   When decomposing matrix $A$ into $A=LU$, it may be beneficial to swap rows to get the largest values on the diagonal of $U$ (pivoting). A permutation matrix $P$ is used to store row swapping such that:
   \[
    PA = LU
   \]
  \begin{itemize}
    \item Write down a permutation matrix and the linear system
    \item Promote the largest value in the column diagonal
    \item Eliminate all elements below diagonal
    \item Move on to the next column and move largest elements to diagonal
    \item Eliminate elements below diagonal
    \item Repeat 5 and 6
    \item Write down L,U and P
  \end{itemize}
\end{frame}

\subsection*{LU decomposition with pivoting-example}
\begin{frame}[fragile]
  \frametitle{LU decomposition example (1)}
  Write down a permutation matrix, which starts as the identity matrix, and the linear system:
  \begin{align*}
    PA &= LU \\
    \begin{bmatrix}
      1 & 0 & 0\\
      0 & 1 & 0\\
      0 & 0 & 1
    \end{bmatrix} 
    \begin{bmatrix}
      0 & 1 & 1\\
      2 & 1 & 1\\
      1 & 2 & 0
      \end{bmatrix}&= 
      \begin{bmatrix}
      1 & 0 & 0\\
      0 & 1 & 0\\
      0 & 0 & 1
      \end{bmatrix}
      \begin{bmatrix}
      0 & 1 & 1\\
      2 & 1 & 1\\
      1 & 2 & 0
      \end{bmatrix}
  \end{align*}
  \pause
  Promote the largest value into the diagonal of column 0 --- swap row 0 and 1:
    \[
      \begin{bmatrix}
	\tikzmarkin[txt=style yellow]{am1} 0 & 1 & 0\\
	1 & 0 & 0 \tikzmarkend{am1}\\
	0 & 0 & 1
      \end{bmatrix} 
      \begin{bmatrix}
	0 & 1 & 1\\
	2 & 1 & 1\\
	1 & 2 & 0
      \end{bmatrix}= 
      \begin{bmatrix}
	1 & 0 & 0\\
	0 & 1 & 0\\
	0 & 0 & 1
      \end{bmatrix}
      \begin{bmatrix}
	\tikzmarkin[txt=style yellow]{am2}2 & 1 & 0\\
	0 & 1 & 1 \tikzmarkend{am2}\\
	1 & 2 & 0
      \end{bmatrix}
    \]
\end{frame}
% 
\begin{frame}[fragile]
  \frametitle{LU decomposition example (2)}
  Eliminate all \tikzmarkin[txt=style orange]{lu1}elements below the diagonal\tikzmarkend{lu1} --- row 1 already contains a zero in column 0, row 2 = row 2 - 0.5 row 0. Record the \tikzmarkin[txt=style cyan]{lu2}multiplier 0.5\tikzmarkend{lu2} in $L$:
  \[
    \begin{bmatrix}
      0 & 1 & 0\\
      1 & 0 & 0\\
      0 & 0 & 1
    \end{bmatrix} 
    \begin{bmatrix}
      0 & 1 & 1\\
      2 & 1 & 1\\
      1 & 2 & 0
      \end{bmatrix}= 
      \begin{bmatrix}
      1 & 0 & 0\\
      0 & 1 & 0\\
      \tikzmarkin[txt=style cyan]{lu3}0.5\tikzmarkend{lu3} & 0 & 1
      \end{bmatrix}
      \begin{bmatrix}
      2 & 1 & 1\\
      \tikzmarkin[txt=style orange]{lu4}0 & 1 & 1\\
      0\tikzmarkend{lu4} & 1.5 & -0.5
      \end{bmatrix}
  \]
  \pause
  Elimination of column 0 is done. Step to the next column, and move the largest value below/on the diagonal to the diagonal (~\tikzmarkin[txt=style yellow]{lu8}swap rows 1 and 2\tikzmarkend{lu8}~). Adjust $P$ and \tikzmarkin[txt=style green]{lu9}lower triangle of $L$\tikzmarkend{lu9} accordingly:
  \[
    \begin{bmatrix}
      0 & 1 & 0\\
      \tikzmarkin[txt=style yellow]{lu5} 0 & 0 & 1 \\
      1 & 0 & 0\tikzmarkend{lu5}
    \end{bmatrix} 
    \begin{bmatrix}
      0 & 1 & 1\\
      2 & 1 & 0\\
      1 & 2 & 0
      \end{bmatrix}= 
      \begin{bmatrix}
      1 & 0 & 0\\
      \tikzmarkin[draw=none,txt=style green]{lu6}(0.25,-0.15)0.5 & 1 & 0\\
      \tikzmarkin[draw=none,txt=style green]{lu10}0\tikzmarkend{lu6} & 0\tikzmarkend{lu10} & 1
      \end{bmatrix}
      \begin{bmatrix}
      2 & 1 & 1\\
      \tikzmarkin[txt=style yellow]{lu7}(0.4,-0.15) 0 & 1.5 & -0.5 \\
      0 & 1 & 1\tikzmarkend{lu7}
      \end{bmatrix}
  \]
\end{frame}

\begin{frame}[fragile]
  \frametitle{LU decomposition example (3)}
    Eliminate \tikzmarkin[txt=style orange]{f3}all elements below the diagonal\tikzmarkend{f3} ---\\
    row 2 = row 2 - $\frac{2}{3}$row 1. Record the multiplier \tikzmarkin[txt=style green]{f1}$\frac{2}{3}$\tikzmarkend{f1} in $L$:
  \[
    \begin{bmatrix}
      0 & 1 & 0\\
      0 & 0 & 1 \\
      1 & 0 & 0
    \end{bmatrix} 
    \begin{bmatrix}
      0 & 1 & 1\\
      2 & 1 & 0\\
      1 & 2 & 0
      \end{bmatrix}= 
      \begin{bmatrix}
      1 & 0 & 0\\
      0.5 & 1 & 0\\
      0 & \tikzmarkin[txt=style green]{f2}\frac{2}{3}\tikzmarkend{f2} & 1
      \end{bmatrix}
      \begin{bmatrix}
      2 & 1 & 1\\
      0 & 1.5 & -0.5 \\
      0 & \tikzmarkin[txt=style orange]{f4}0\tikzmarkend{f4} & \frac{4}{3}\\
      \end{bmatrix}
  \]
  \pause
  We have obtained the matrices from $PA=LU$:
  \[
    P = \begin{bmatrix}
      0 & 1 & 0\\
      0 & 0 & 1 \\
      1 & 0 & 0
    \end{bmatrix} \quad
    L=\begin{bmatrix}
      1 & 0 & 0\\
      0.5 & 1 & 0\\
      0 & \frac{2}{3} & 1
      \end{bmatrix} \quad
      U = \begin{bmatrix}
      2 & 1 & 1\\
      0 & 1.5 & -0.5 \\
      0 & 0 & \frac{4}{3}\\
      \end{bmatrix}
  \]
  Proceed with solving for $x$.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Substitutions}
  \vskip-2em
  \begin{align*}
    Ax = b \quad  &\Rightarrow \quad PAx=Pb\equiv d\\
    PA = LU \quad&\Rightarrow \quad LUx = d
  \end{align*}
%   \vskip-1ex
  \begin{itemize}
    \item Define a new vector $y=Ux$
    \begin{itemize}
      \item $Ly=b \quad\Rightarrow\quad Ly = d$
      \item Solve for $y$, forward substitution:
      \begin{align*}
	y_1 &= \frac{d_1}{L_{11}} \\
	y_i &= \frac{d_i - \sum_{j=1}^{i-1}L_{ij}y_j}{L_{ii}}
      \end{align*}
    \end{itemize}
    \item Then solve $Ux=y$:
    \begin{itemize}
      \item Solve for $x$, backward substitution:
      \begin{align*}
	x_N &= \frac{y_N}{U_{NN}} \\
	x_i &= \frac{y_i - \sum_{j=i+1}^{N-1}U_{ij}x_j}{U_{ii}}
      \end{align*}
    \end{itemize}      
  \end{itemize}  
\end{frame}

\subsection*{Using LU in Python}
\begin{frame}[fragile]
  \frametitle{How to use the LU solver in Python}
  \begin{lstlisting}
import numpy as np
import scipy.linalg as spla
from gaussian_elimination import forwardsubstitution, backsubstitution

N = 5 #Number of equations to generate
A = np.random.rand(N,N)      # Create random matrix
b = np.random.rand(N,1)      # Create random right-hand side

P, L, U = spla.lu(A);        # Get P, L and U
d = P.T@b;                   # Permute b vector 
y = forwardsubstitution(L,d) # Alternative: y = spla.solve(L,d)
x = backsubstitution(U,y)    # Alternative: x = spla.solve(U,y)

print(f'Using LU decomposition:\n{x}')
print(f'Conventional method:\n {spla.solve(A,b)}')
print(f'Residual norm: {spla.norm(A@x-b)}')
  \end{lstlisting}
  \pause
  \begin{itemize}
     \item Use this as a basis to create a function that takes $A$ and $b$, and returns $x$.
     \item Use the function to check the performance for various matrix sizes and inspect the performance.
  \end{itemize}

\end{frame}
\section{Summary}
\subsection*{Summary}
\againframe<2>{contents_lin2}

\begin{frame}[fragile]
  \frametitle{Summary}
  \begin{itemize}
    \item This lecture covered direct methods using elimination techniques.
    \item Gaussian elimination can be slow ($\mathcal{O}(N^3)$)
    \item Back substitution is often faster ($\mathcal{O}(N^2)$)
    \item LU decomposition means that we don't have to do Gaussian elimination every time (saves time and effort), but the matrix has to stay the same.
    \item Matlab has build in routines for solving linear equations (backslash operator \lstinline$\$) and LU decomposition (\lstinline$lu$).
    \item Advanced techniques such as (preconditioned) conjugate gradient or biconjugate gradient solvers are also available.
    \item Next part covers iterative approaches
\end{itemize}
\end{frame}
