\part{Systems of linear equations I - Direct methods}
\section{Introduction}
\subsection*{General}
\begin{frame}[label=contents_lin2]
  \frametitle{Today's outline}
  \mode<beamer>{
    \only<1>{\tableofcontents}
  }
  \only<2>{\tableofcontents[currentsection,currentsubsection]}
\end{frame}

\begin{frame}
  \frametitle{Overview}
  \begin{block}{Goals}
    Today we are going to write a program, which can solve a set of linear equations
    \begin{itemize}
      \item The first method is called Gaussian elimination
      \item We will encounter some problems with Gaussian elimination
      \item Then LU decomposition will be introduced
  \end{itemize}
  \end{block}
\end{frame}

\section{Gauss elimination}
\subsection*{Row operations}
\againframe<2>{contents_lin2}
\frame{
  \frametitle{Define the linear system}
   Consider the system: 
   \[
      Ax = b
   \]
   \vfill
   In general:
    \[ 
    \begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
A_{10} & A_{11} & A_{12}\\ 
A_{20} & A_{21} & A_{22}
\end{bmatrix}\begin{bmatrix}
x_0\\x_1\\x_2  
\end{bmatrix}=\begin{bmatrix}b_0\\b_1\\b_2  \end{bmatrix} 
\]
  \vfill
Desired solution:
    \[ 
    \begin{bmatrix}
1 & 0 & 0\\ 
0 & 1 & 0\\ 
0 & 0 & 1
\end{bmatrix}\begin{bmatrix}
x_0\\x_1\\x_2  
\end{bmatrix}=\begin{bmatrix}b'_0\\b'_1\\b'_2\end{bmatrix} 
\]
}

\begin{frame}[fragile]
  \frametitle{Using row operations}
  \begin{itemize}
    \item Use row operations to simplify the system. Eliminate element $A_{10}$ by subtracting $A_{10}/A_{00} = d_{10}$ times row 1 from row 2.
    \item In this case, Row 1 is the pivot row, and $A_{00}$ is the pivot element.
  \end{itemize}
  \tikz{\node (m1) {
    $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      \tikzmarkin[txt=style yellow]{a21a} A_{10} & A_{11} & A_{12} & b_1\tikzmarkend{a21a}\\ 
      A_{20} & A_{21} & A_{22} & b_2
    \end{array}\right]
  $};
  \node[right=2cm of m1,](m2){
  $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      \tikzmarkin[txt=style yellow] {a21b} 0      & A'_{11} & A'_{12} & b'_1\tikzmarkend{a21b}\\ 
      A_{20} & A_{21} & A_{22} & b_2
    \end{array}\right]
  $};
  \draw[->,thick] (m1.east) --  (m2.west);
  }
\end{frame}

\begin{frame}[fragile]
  \frametitle{Using row operations}
  Eliminate element $A_{10}$ using $d_{10}=A_{10}/A_{00}$.
  \vfill
    \tikz{\node (m1) {
    $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      \tikzmarkin[txt=style yellow] {a211}A_{10} & A_{11} & A_{12} & b_1\tikzmarkend{a211}\\ 
      A_{20} & A_{21} & A_{22} & b_2
    \end{array}\right]
  $};
  \node[right=2cm of m1,](m2){
  $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      \tikzmarkin[txt=style yellow] {a212} 0      & A'_{11} & A'_{12} & b'_1\tikzmarkend{a212}\\ 
      A_{20} & A_{21} & A_{22} & b_2
    \end{array}\right]
  $};
  \draw[->,thick] (m1.east) --  (m2.west);
  }
  \vfill\pause
  \begin{columns}
  \column{0.4\textwidth}
  \begin{itemize}
    \item $d_{10}\rightarrow A_{10}/A_{00}$
    \item $A_{10}\rightarrow A_{10}-A_{00}d_{10}$
    \item $A_{11}\rightarrow A_{11}-A_{01}d_{10}$
    \item $A_{12}\rightarrow A_{12}-A_{02}d_{10}$
    \item $b_1   \rightarrow b_1   -b_0   d_{10}$
  \end{itemize}
  \pause
  \column{0.6\textwidth}
   \begin{lstlisting}
d10 = A[1,0] / A[0,0]

A[1,0] = A[1,0] - A[0,0] * d10
A[1,1] = A[1,1] - A[0,1] * d10
A[1,2] = A[1,2] - A[0,2] * d10

b[1] = b[1] - b[0] * d10
   \end{lstlisting}
  \end{columns}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Using row operations}
  Eliminate element $A_{20}$ using $d_{20}=A_{20}/A_{00}$.
  \vfill
    \tikz{\node (m1) {
    $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      0 & A'_{11} & A'_{12} & b'_1\\ 
      \tikzmarkin[txt=style yellow] {a311}A_{20} & A_{21} & A_{22} & b_2\tikzmarkend{a311}
    \end{array}\right]
  $};
  \node[right=2cm of m1,](m2){
  $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      0      & A'_{11} & A'_{12} & b'_1\\ 
      \tikzmarkin[txt=style yellow] {a312}0 & A'_{21} & A'_{22} & b'_2\tikzmarkend{a312}
    \end{array}\right]
  $};
  \draw[->,thick] (m1.east) --  (m2.west);
  }
  \vfill\pause
  \begin{columns}
  \column{0.4\textwidth}
  \begin{itemize}
    \item $d_{20}\rightarrow A_{20}/A_{00}$
    \item $A_{20}\rightarrow A_{20}-A_{00}d_{20}$
    \item $A_{21}\rightarrow A_{21}-A_{01}d_{20}$
    \item $A_{22}\rightarrow A_{22}-A_{02}d_{20}$
    \item $b_2   \rightarrow b_2   -b_0   d_{20}$
  \end{itemize}
  \column{0.6\textwidth}
  \begin{lstlisting}
d20 = A[2, 0] / A[0, 0]

A[2, 0] = A[2, 0] - A[0, 0] * d20
A[2, 1] = A[2, 1] - A[0, 1] * d20
A[2, 2] = A[2, 2] - A[0, 2] * d20
b[2] = b[2] - b[0] * d20
  \end{lstlisting}
  \end{columns}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Using row operations}
  Eliminate element $A'_{21}$ using $d_{21}=A'_{21}/A'_{11}$. Note that now the second row has become the pivot row.
  \vfill
    \tikz{\node (m1) {
    $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      0 & A'_{11} & A'_{12} & b'_1\\ 
      \tikzmarkin[txt=style yellow] {a311b} 0 & A'_{21} & A'_{22} & b'_2\tikzmarkend{a311b}
    \end{array}\right]
  $};
  \node[right=2cm of m1,](m2){
  $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      0      & A'_{11} & A'_{12} & b'_1\\ 
      \tikzmarkin[txt=style yellow] {a312b}0 & 0 & A''_{22} & b''_2\tikzmarkend{a312b}
    \end{array}\right]
  $};
  \draw[->,thick] (m1.east) --  (m2.west);
  }
  \vfill\pause
  \begin{columns}
  \column{0.4\textwidth}
  \begin{itemize}
    \item $d_{21}\rightarrow A_{21}/A'_{11}$
    \item $A_{21}\rightarrow A_{21}-A'_{11}d_{21}$
    \item $A_{22}\rightarrow A_{22}-A'_{12}d_{21}$
    \item $b_2   \rightarrow b_2   -b'_2   d_{21}$
  \end{itemize}
  \column{0.6\textwidth}
   \begin{lstlisting}
d21 = A[2, 1] / A[1, 1]
A[2, 1] = A[2, 1] - A[1, 1] * d21
A[2, 2] = A[2, 2] - A[1, 2] * d21
b[2] = b[2] - b[1] * d21
   \end{lstlisting}
  \end{columns}
  \pause
  \vfill
  The matrix is now a triangular matrix --- the solution can be obtained by back-substitution.
\end{frame}

\subsection*{Backsubstitution}
\begin{frame}[fragile]
  \frametitle{Backsubstitution}
  The system now reads:
  \[
    \begin{bmatrix}
      A_{00} & A_{01} & A_{02}\\ 
      0      & A'_{11} & A'_{12}\\ 
      0 & 0 & A''_{22}
    \end{bmatrix}
    \begin{bmatrix}x_0\\x_1\\x_2\end{bmatrix} = 
    \begin{bmatrix}b_0\\b'_1\\b''_2\end{bmatrix}
  \]
  \pause
  Start at the last row $N$, and work upward until row 1.
  \begin{columns}
  \column{0.4\textwidth}
    \begin{align*}
     x_2 &= b''_2/A''_{22}\\
     x_1 &= (b'_1 - A'_{12}x_2)/A'_{11}\\
     x_0 &= (b_0 - A_{01}x_1 - A_{02}x_2)/A_{00}
    \end{align*}
    \pause
  \column{0.6\textwidth}
    \begin{lstlisting}
x = np.empty_like(b)
x[2] = b[2] / A[2,2]
x[1] = (b[1] - A[1,2] * x[2]) / A[1,1]
x[0] = (b[0] - A[0,1] * x[1] - A[0,2] * x[2]) / A[0,0]
    \end{lstlisting}
\end{columns}
In general:
\[
 x_N = \frac{b_N}{A_{NN}} \qquad x_i = \frac{b_i - \sum_{j=i+1}^{N}A_{ij}x_j}{A_{ii}}
\]
\end{frame}

\begin{frame}[fragile]
  \frametitle{Writing the program}
  \begin{itemize}
   \item Create a function that provides the framework: take matrix $A$ and vector $b$ as an input, and return the solution $x$ as output:
  \begin{lstlisting}[language=Python]
def gaussian_eliminate(A, b):
    pass  # Your implementation here
  \end{lstlisting}
  \item We will use \emph{for-loops} instead of typing out each command line.
  \item Useful Python (with NumPy) shortcuts:
  \begin{itemize}
  \item \lstinline[language=Python]$A[0, :]$   = $[A_{00}, A_{01}, A_{02}]$
  \item \lstinline[language=Python]$A[:, 1]$   = $[A_{01}, A_{11}, A_{21}]$
  \item \lstinline[language=Python]$A[0, 1:]$ = $[A_{01}, A_{02}]$
  \end{itemize}
  \item A row operation could look like:
  \begin{lstlisting}[language=Python]
A[i, :] = A[i, :] - d * A[0, :]   
  \end{lstlisting}
  \end{itemize}
\end{frame}


\begin{frame}[fragile]
  \frametitle{The program: elimination step}
  An initial draft could look like:
  \begin{lstlisting}
def gaussian_eliminate_draft(A,b):
    """Perform elimination to obtain an upper triangular matrix"""
    A = np.array(A,dtype=np.float64)
    b = np.array(b,dtype=np.float64)

    assert A.shape[0] == A.shape[1], "Coefficient matrix should be square"

    N = len(b)
    for col in range(N-1):                # Select pivot
        for row in range(col+1,N):        # Loop over rows below pivot
            d = A[row,col] / A[col,col]   # Choose elimination factor
            for element in range(row,N):  # Elements from diagonal to right
                A[row,element] = A[row,element] - d * A[col,element]
            b[row] = b[row] - d * b[col]

    return A,b
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
  \frametitle{The program: elimination step}
  Employing some of the row operations to create \lstinline|gaussian_eliminate_v1|:
  \begin{columns}[T]
    \column{0.6\textwidth}
    \begin{lstlisting}
for element in range(row,N):
    A[row,element] = A[row,element] - d * A[col,element]
        \end{lstlisting}    
    \column{0.4\textwidth}
    \begin{lstlisting}
A[row,:] = A[row,:] - d * A[col,:]
        \end{lstlisting}
  \end{columns}
  \pause
  \begin{lstlisting}
def gaussian_eliminate_v1(A,b):
    A = np.array(A,dtype=np.float64)
    b = np.array(b,dtype=np.float64)

    assert A.shape[0] == A.shape[1], "Coefficient matrix should be square"

    N = len(b)
    for col in range(N-1):
        for row in range(col+1,N):
            d = A[row,col] / A[col,col]
            A[row,:] = A[row,:] - d * A[col,:]
            b[row] = b[row] - d * b[col]

    return A,b
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Testing}
  Let's try to eliminate our linear system! If you create/downloaded our file \lstinline|gaussjordan.py|, you can access the functions by importing them. The file should be stored where your own code/notebook is:
  \begin{lstlisting}
from gaussjordan import gaussian_eliminate_draft,gaussian_eliminate_v1
import numpy as np

A = np.array([[1, 1, 1], [2, 1, 3], [3, 1, 6]]) 
b = np.array([4, 7, 5]) 

Aprime,bprime = gaussian_eliminate_draft(A,b)
print(Aprime)
print(bprime)
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
  \frametitle{The program: Backsubstitution}
  Now we have elimination working, let's create a back substitution algorithm too. Recall:
  \[
    x_N = \frac{b_N}{A_{NN}} \qquad x_i = \frac{b_i - \sum_{j=i+1}^{N}A_{ij}x_j}{A_{ii}}
 \]
 \begin{columns}[T]
  \column{0.4\textwidth}
  \begin{lstlisting}[basicstyle=\tiny\ttfamily]
def backsubstitution_draft(A, b):
    """Back substitutes an upper triangular matrix to find x in Ax=b"""
    x = np.copy(b)
    N = len(b)

    for row in range(N-1, -1, -1):
        for i in range(row+1, N):
            x[row] = x[row] - A[row, i] * x[i]
        x[row] = x[row] / A[row, row]  
    
    return x
      \end{lstlisting}\pause
  \column{0.6\textwidth}
  \begin{lstlisting}[basicstyle=\tiny\ttfamily]
def backsubstitution_v1(A,b):
    """Back substitutes an upper triangular matrix to find x in Ax=b"""
    x = np.empty_like(b)
    N = len(b)
    
    for row in range(N)[::-1]:
        x[row] = (b[row] - np.sum(A[row,row+1:] * x[row+1:])) / A[row,row]

    return x
      \end{lstlisting}
 \end{columns}
\end{frame}

% \begin{frame}[fragile]
%   \frametitle{The program: Backsubstitution}
%   \begin{lstlisting}
% def backsubstitution_v1(A,b):
%     """Back substitutes an upper triangular matrix to find x in Ax=b"""
%     x = np.empty_like(b)
%     N = len(b)
    
%     for row in range(N)[::-1]:
%         x[row] = (b[row] - np.sum(A[row,row+1:] * x[row+1:])) / A[row,row]

%     return x
%   \end{lstlisting}
%   \[
%      x_N = \frac{b_N}{A_{NN}} \qquad x_i = \frac{b_i - \sum_{j=i+1}^{N}A_{ij}x_j}{A_{ii}}
%   \]
% \end{frame}

\begin{frame}[fragile]
  \frametitle{A full Gauss Elimination solver}
  \begin{itemize}
    \item The functions we just built are distributed in a Python module
    \item Use \lstinline$help GaussianEliminate$ to find out how it works
    \item Solve the following system of equations:
    \[
    \begin{bmatrix}
      9 & 9 & 5 & 2\\ 
      6 & 7 & 1 & 3\\ 
      6 & 4 & 3 & 5\\
      2 & 6 & 2 & 1
    \end{bmatrix}
    \begin{bmatrix}x_1\\x_2\\x_3\\x_4\end{bmatrix} = 
    \begin{bmatrix}7\\4\\10\\1\end{bmatrix}
  \]
  \item Compare your solution with \lstinline$np.linalg.solve(A,b)$
  \end{itemize}
\end{frame}

\section{Partial Pivoting}
\subsection*{Pivoting}
\againframe<2>{contents_lin2}

\begin{frame}[fragile]
  \frametitle{Partial pivoting}
  \begin{itemize}
    \item Now try to run the algorithm with the following system:
    \[
    \begin{bmatrix}
      0 & 2 & 1\\ 
      3 & 2 & 1 \\ 
      1 & 1 & 1
    \end{bmatrix}
    \begin{bmatrix}x_1\\x_2\\x_3\end{bmatrix} = 
    \begin{bmatrix}4\\3\\10\end{bmatrix}
  \]
  \pause
  \item It does not work! Division by zero, due to $A_{11}=0$.
  \item Solution: Swap rows to move largest element to the diagonal.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Partial pivoting: implementing row swaps}
  \begin{itemize}[<+->]
    \item Find maximum element row in $A$ below pivot in current column, store the index
    \begin{lstlisting}[numbers=none]
index = np.argmax(np.abs(A[col:, col])) + col 
    \end{lstlisting}
    \item Swap rows through indexing (i.e. select rows by their index).
    \begin{lstlisting}[numbers=none]
A[[i,col]] = A[[col,i]]
    \end{lstlisting}
    \item Do the same for \lstinline$b$ --- swap through indexing
    \begin{lstlisting}[numbers=none]
b[[i,col]] = b[[col,i]]
      \end{lstlisting}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Adding the partial pivoting rules}
  \begin{lstlisting}[language=Python]
def gaussian_eliminate_partial_pivot(A,b):
    A = np.array(A,dtype=np.float64)
    b = np.array(b,dtype=np.float64)

    assert A.shape[0] == A.shape[1], "Coefficient matrix should be square"

    N = len(b)
    for col in range(N-1):
        index = np.argmax(np.abs(A[col:, col])) + col
        A[[i,col]] = A[[col,i]]
        b[[i,col]] = b[[col,i]]

        for row in range(col+1,N):
            d = A[row,col] / A[col,col]
            A[row,:] = A[row,:] - d * A[col,:]
            b[row] = b[row] - d * b[col]

    return A,b
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Alternatives to this program}
  \begin{itemize}
    \item Python can compute the solution to Ax=b with \lstinline|scipy.linalg.solve| or \lstinline|numpy.linalg.solve| solvers (more efficient)
    \item Too many loops. Loops make Python slow.
    \item There are fundamental problems with Gaussian elimination\pause
    \begin{itemize}
      \item You can add a counter to the algorithm to see how many subtraction and multiplication operations it performs for a given size of matrix A.
      \item The number of operations to perform Gaussian elimination is $\mathcal{O}(2N^3)$ (where $N$ is the number of equations) 
      \item Exercise: verify this for our script \pause
      \item LU decomposition takes $\mathcal{O}(2N^3/3)$ flops, 3 times less!
      \item Forward and backward substitution each take $\mathcal{O}(N^2)$
flops (both cases) 
    \end{itemize}
  \end{itemize}
\end{frame}

\section{LU decomposition}
\subsection*{LU}
\againframe<2>{contents_lin2}

\begin{frame}[fragile]
  \frametitle{LU Decomposition}
  Suppose we want to solve the previous set of equations, but with several right hand sides:
    \[ 
    \begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
A_{21} & A_{22} & A_{23}\\ 
A_{31} & A_{32} & A_{33}
\end{bmatrix}
\begin{bmatrix}
\vdots & \vdots & \vdots \\
x_1 & x_2 & x_3 \\
\vdots & \vdots & \vdots
\end{bmatrix} = 
\begin{bmatrix}
\vdots & \vdots & \vdots \\
b_1 & b_2 & b_3 \\
\vdots & \vdots & \vdots
\end{bmatrix}
\]\pause
Factor the matrix A into two matrices, L and U, such that $A=LU$:
\[ 
    \begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
A_{21} & A_{22} & A_{23}\\ 
A_{31} & A_{32} & A_{33}
\end{bmatrix} = 
\begin{bmatrix}
1 & 0 & 0 \\
\times & 1 & 0 \\
\times & \times & 1
\end{bmatrix}
\begin{bmatrix}
\times & \times & \times \\
0 & \times & \times \\
0 & 0 & \times
\end{bmatrix}
\]
Now we can solve for each right hand side, using only a forward
followed by a backward substitution!
\end{frame}

\begin{frame}[fragile]
  \frametitle{Substitutions}
  \begin{itemize}
    \item Define $L$ and $U$ such that $A = LU$
    \item Therefore $Ax = LUx = b$
    \item Define a new vector $y = Ux$ so that $Ly = b$
    \item Solve for $y$, use $L$ and forward substitution
    \item Then we have $y$, solve for $x$, use $Ux = y$
    \item Solve for $x$, use $U$ and backward substitution
    \item But how to get L and U?
    \begin{itemize}
      \item Gaussian elimination
      \item Doolittle's decomposition
      \item Crout's decomposition
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Recipe for LU decomposition}
  LU decomposition can be done in Python using \lstinline|scipy.linalg.lu|. Row swapping is done to get the largest values on the main diagonal of $U$ (pivoting). A permutation matrix $P$ is used to store row swapping such that:
   \[
    PA = LU
   \]
   Matrix $P$ is returned in addition to $L$ and $U$:
  \begin{columns}[T]
    \column{0.7\textwidth}
      \begin{lstlisting}
from scipy.linalg import lu
A = np.array([[1,1,1],[2,1,3],[3,1,6]])
P,L,U = lu(A)
with np.printoptions(precision=2, threshold=5):
    print(P,L,U,sep='\n\n')
      \end{lstlisting}
    \column{0.3\textwidth}
      \begin{lstlisting}[style=PyOutput,keepspaces=true]
[[0. 1. 0.]
 [0. 0. 1.]
 [1. 0. 0.]]

[[1.   0.   0.  ]
 [0.33 1.   0.  ]
 [0.67 0.5  1.  ]]

[[ 3.    1.    6.  ]
 [ 0.    0.67 -1.  ]
 [ 0.    0.   -0.5 ]]
      \end{lstlisting}
  \end{columns}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Substitutions}
  \vskip-2em
  \begin{align*}
    Ax = b \quad  &\Rightarrow \quad PAx=Pb\equiv d\\
    PA = LU \quad&\Rightarrow \quad LUx = d
  \end{align*}
%   \vskip-1ex
  \begin{itemize}
    \item Define a new vector $y=Ux$
    \begin{itemize}
      \item $Ly=b \quad\Rightarrow\quad Ly = d$
      \item Solve for $y$, forward substitution:
      \begin{align*}
	y_0 &= \frac{d_0}{L_{00}} \\
	y_i &= \frac{d_i - \sum_{j=0}^{i}L_{ij}y_j}{L_{ii}}
      \end{align*}
    \end{itemize}
    \item Then solve $Ux=y$:
    \begin{itemize}
      \item Solve for $x$, backward substitution:
      \begin{align*}
	x_N &= \frac{y_N}{U_{NN}} \\
	x_i &= \frac{y_i - \sum_{j=i+1}^{N}U_{ij}x_j}{U_{ii}}
      \end{align*}
    \end{itemize}      
  \end{itemize}  
\end{frame}

\subsection*{Using LU in Python}
\begin{frame}[fragile]
  \frametitle{How to use the solver in Python}
  \begin{lstlisting}[language=Python]
import numpy as np
from scipy.linalg import lu
from gaussjordan import backsubstitution_v1 as backwardSub
from gaussjordan import forwardsubstitution as forwardSub

# Example usage
A = np.random.rand(5, 5)  # Get random matrix
P, L, U = lu(A)           # Get L, U and P
b = np.random.rand(5)     # Random b vector
d = P @ b                 # Permute b vector
y = forwardSub(L, d)      # Can also do y=np.linalg.solve(L,d)
x = backwardSub(U, y)     # Can also do x=np.linalg.solve(U,y)
rnorm = np.linalg.norm(A @ x - b)  # Residual
  \end{lstlisting}
  \pause
  \begin{itemize}
     \item Use this as a basis to create a function that takes $A$ and $b$, and returns $x$.
     \item Use the function to check the performance for various matrix sizes and inspect the performance.
  \end{itemize}

\end{frame}
\section{Summary}
\subsection*{Summary}
\againframe<2>{contents_lin2}

\begin{frame}[fragile]
  \frametitle{Summary}
  \begin{itemize}
    \item This lecture covered direct methods using elimination techniques.
    \item Gaussian elimination can be slow ($\mathcal{O}(N^3)$)
    \item Back substitution is often faster ($\mathcal{O}(N^2)$)
    \item LU decomposition means that we don't have to do Gaussian elimination every time (saves time and effort), but the matrix has to stay the same.
    \item Python's libraries have built in routines for solving linear equations and LU decomposition.
    \item Advanced techniques such as (preconditioned) conjugate gradient or biconjugate gradient solvers are also available.
    \item Next part covers iterative approaches
\end{itemize}
\end{frame}
