\part{Systems of linear equations I - Direct methods}
\section{Introduction}
\subsection*{General}
\begin{frame}[label=contents_lin2]
  \frametitle{Today's outline}
  \mode<beamer>{
    \only<1>{\tableofcontents}
  }
  \only<2>{\tableofcontents[currentsection,currentsubsection]}
\end{frame}

\begin{frame}
  \frametitle{Overview}
  \begin{block}{Goals}
    Today we are going to write a program, which can solve a set of linear equations
    \begin{itemize}
      \item The first method is called Gaussian elimination
      \item We will encounter some problems with Gaussian elimination
      \item Then LU decomposition will be introduced
  \end{itemize}
  \end{block}
\end{frame}

\section{Gauss elimination}
\subsection*{Row operations}
\againframe<2>{contents_lin2}
\frame{
  \frametitle{Define the linear system}
   Consider the system: 
   \[
      Ax = b
   \]
   \vfill
   In general:
    \[ 
    \begin{bmatrix}
A_{00} & A_{01} & A_{02}\\ 
A_{10} & A_{11} & A_{12}\\ 
A_{20} & A_{21} & A_{22}
\end{bmatrix}\begin{bmatrix}
x_0\\x_1\\x_2  
\end{bmatrix}=\begin{bmatrix}b_0\\b_1\\b_2  \end{bmatrix} 
\]
  \vfill
Desired solution:
    \[ 
    \begin{bmatrix}
1 & 0 & 0\\ 
0 & 1 & 0\\ 
0 & 0 & 1
\end{bmatrix}\begin{bmatrix}
x_0\\x_1\\x_2  
\end{bmatrix}=\begin{bmatrix}b'_0\\b'_1\\b'_2\end{bmatrix} 
\]
}

\begin{frame}[fragile]
  \frametitle{Using row operations}
  \begin{itemize}
    \item Use row operations to simplify the system. Eliminate element $A_{10}$ by subtracting $A_{10}/A_{00} = d_{10}$ times row 1 from row 2.
    \item In this case, Row 1 is the pivot row, and $A_{00}$ is the pivot element.
  \end{itemize}
  \tikz{\node (m1) {
    $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      \tikzmarkin[txt=style yellow]{a21a} A_{10} & A_{11} & A_{12} & b_1\tikzmarkend{a21a}\\ 
      A_{20} & A_{21} & A_{22} & b_2
    \end{array}\right]
  $};
  \node[right=2cm of m1,](m2){
  $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      \tikzmarkin[txt=style yellow] {a21b} 0      & A'_{11} & A'_{12} & b'_1\tikzmarkend{a21b}\\ 
      A_{20} & A_{21} & A_{22} & b_2
    \end{array}\right]
  $};
  \draw[->,thick] (m1.east) --  (m2.west);
  }
\end{frame}

\begin{frame}[fragile]
  \frametitle{Using row operations}
  Eliminate element $A_{10}$ using $d_{10}=A_{10}/A_{00}$.
  \vfill
    \tikz{\node (m1) {
    $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      \tikzmarkin[txt=style yellow] {a211}A_{10} & A_{11} & A_{12} & b_1\tikzmarkend{a211}\\ 
      A_{20} & A_{21} & A_{22} & b_2
    \end{array}\right]
  $};
  \node[right=2cm of m1,](m2){
  $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      \tikzmarkin[txt=style yellow] {a212} 0      & A'_{11} & A'_{12} & b'_1\tikzmarkend{a212}\\ 
      A_{20} & A_{21} & A_{22} & b_2
    \end{array}\right]
  $};
  \draw[->,thick] (m1.east) --  (m2.west);
  }
  \vfill\pause
  \begin{columns}
  \column{0.4\textwidth}
  \begin{itemize}
    \item $d_{10}\rightarrow A_{10}/A_{00}$
    \item $A_{10}\rightarrow A_{10}-A_{00}d_{10}$
    \item $A_{11}\rightarrow A_{11}-A_{01}d_{10}$
    \item $A_{12}\rightarrow A_{12}-A_{02}d_{10}$
    \item $b_1   \rightarrow b_1   -b_0   d_{10}$
  \end{itemize}
  \pause
  \column{0.6\textwidth}
   \begin{lstlisting}
d10 = A[1,0] / A[0,0]

A[1,0] = A[1,0] - A[0,0] * d10
A[1,1] = A[1,1] - A[0,1] * d10
A[1,2] = A[1,2] - A[0,2] * d10

b[1] = b[1] - b[0] * d10
   \end{lstlisting}
  \end{columns}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Using row operations}
  Eliminate element $A_{20}$ using $d_{20}=A_{20}/A_{00}$.
  \vfill
    \tikz{\node (m1) {
    $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      0 & A'_{11} & A'_{12} & b'_1\\ 
      \tikzmarkin[txt=style yellow] {a311}A_{20} & A_{21} & A_{22} & b_2\tikzmarkend{a311}
    \end{array}\right]
  $};
  \node[right=2cm of m1,](m2){
  $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      0      & A'_{11} & A'_{12} & b'_1\\ 
      \tikzmarkin[txt=style yellow] {a312}0 & A'_{21} & A'_{22} & b'_2\tikzmarkend{a312}
    \end{array}\right]
  $};
  \draw[->,thick] (m1.east) --  (m2.west);
  }
  \vfill\pause
  \begin{columns}
  \column{0.4\textwidth}
  \begin{itemize}
    \item $d_{20}\rightarrow A_{20}/A_{00}$
    \item $A_{20}\rightarrow A_{20}-A_{00}d_{20}$
    \item $A_{21}\rightarrow A_{21}-A_{01}d_{20}$
    \item $A_{22}\rightarrow A_{22}-A_{02}d_{20}$
    \item $b_2   \rightarrow b_2   -b_0   d_{20}$
  \end{itemize}
  \column{0.6\textwidth}
  \begin{lstlisting}
d20 = A[2, 0] / A[0, 0]

A[2, 0] = A[2, 0] - A[0, 0] * d20
A[2, 1] = A[2, 1] - A[0, 1] * d20
A[2, 2] = A[2, 2] - A[0, 2] * d20
b[2] = b[2] - b[0] * d20
  \end{lstlisting}
  \end{columns}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Using row operations}
  Eliminate element $A'_{21}$ using $d_{21}=A'_{21}/A'_{11}$. Note that now the second row has become the pivot row.
  \vfill
    \tikz{\node (m1) {
    $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      0 & A'_{11} & A'_{12} & b'_1\\ 
      \tikzmarkin[txt=style yellow] {a311b} 0 & A'_{21} & A'_{22} & b'_2\tikzmarkend{a311b}
    \end{array}\right]
  $};
  \node[right=2cm of m1,](m2){
  $
    \left[\begin{array}{ccc|c}
      A_{00} & A_{01} & A_{02} & b_0\\ 
      0      & A'_{11} & A'_{12} & b'_1\\ 
      \tikzmarkin[txt=style yellow] {a312b}0 & 0 & A''_{22} & b''_2\tikzmarkend{a312b}
    \end{array}\right]
  $};
  \draw[->,thick] (m1.east) --  (m2.west);
  }
  \vfill\pause
  \begin{columns}
  \column{0.4\textwidth}
  \begin{itemize}
    \item $d_{21}\rightarrow A_{21}/A'_{11}$
    \item $A_{21}\rightarrow A_{21}-A'_{11}d_{21}$
    \item $A_{22}\rightarrow A_{22}-A'_{12}d_{21}$
    \item $b_2   \rightarrow b_2   -b'_2   d_{21}$
  \end{itemize}
  \column{0.6\textwidth}
   \begin{lstlisting}
d21 = A[2, 1] / A[1, 1]
A[2, 1] = A[2, 1] - A[1, 1] * d21
A[2, 2] = A[2, 2] - A[1, 2] * d21
b[2] = b[2] - b[1] * d21
   \end{lstlisting}
  \end{columns}
  \pause
  \vfill
  The matrix is now a triangular matrix --- the solution can be obtained by back-substitution.
\end{frame}

\subsection*{Backsubstitution}
\begin{frame}[fragile]
  \frametitle{Backsubstitution}
  The system now reads:
  \[
    \begin{bmatrix}
      A_{00} & A_{01} & A_{02}\\ 
      0      & A'_{11} & A'_{12}\\ 
      0 & 0 & A''_{22}
    \end{bmatrix}
    \begin{bmatrix}x_0\\x_1\\x_2\end{bmatrix} = 
    \begin{bmatrix}b_0\\b'_1\\b''_2\end{bmatrix}
  \]
  \pause
  Start at the last row $N$, and work upward until row 1.
  \begin{columns}
  \column{0.4\textwidth}
    \begin{align*}
     x_2 &= b''_2/A''_{22}\\
     x_1 &= (b'_1 - A'_{12}x_2)/A'_{11}\\
     x_0 &= (b_0 - A_{01}x_1 - A_{02}x_2)/A_{00}
    \end{align*}
    \pause
  \column{0.6\textwidth}
    \begin{lstlisting}
x = np.empty_like(b)
x[2] = b[2] / A[2,2]
x[1] = (b[1] - A[1,2] * x[2]) / A[1,1]
x[0] = (b[0] - A[0,1] * x[1] - A[0,2] * x[2]) / A[0,0]
    \end{lstlisting}
\end{columns}
In general:
\[
 x_N = \frac{b_N}{A_{NN}} \qquad x_i = \frac{b_i - \sum_{j=i+1}^{N}A_{ij}x_j}{A_{ii}}
\]
\end{frame}

\begin{frame}[fragile]
  \frametitle{Writing the program}
  \begin{itemize}
   \item Create a function that provides the framework: take matrix $A$ and vector $b$ as an input, and return the solution $x$ as output:
  \begin{lstlisting}[language=Python]
def gaussian_eliminate(A, b):
    pass  # Your implementation here
  \end{lstlisting}
  \item We will use \emph{for-loops} instead of typing out each command line.
  \item Useful Python (with NumPy) shortcuts:
  \begin{itemize}
  \item \lstinline[language=Python]$A[0, :]$   = $[A_{00}, A_{01}, A_{02}]$
  \item \lstinline[language=Python]$A[:, 1]$   = $[A_{01}, A_{11}, A_{21}]$
  \item \lstinline[language=Python]$A[0, 1:]$ = $[A_{01}, A_{02}]$
  \end{itemize}
  \item A row operation could look like:
  \begin{lstlisting}[language=Python]
A[i, :] = A[i, :] - d * A[0, :]   
  \end{lstlisting}
  \end{itemize}
\end{frame}


\begin{frame}[fragile]
  \frametitle{The program: elimination step}
  An initial draft could look like:
  \begin{lstlisting}
def gaussian_eliminate_draft(A,b):
    """Perform elimination to obtain an upper triangular matrix"""
    A = np.array(A,dtype=np.float64)
    b = np.array(b,dtype=np.float64)

    assert A.shape[0] == A.shape[1], "Coefficient matrix should be square"

    N = len(b)
    for col in range(N-1):                # Select pivot
        for row in range(col+1,N):        # Loop over rows below pivot
            d = A[row,col] / A[col,col]   # Choose elimination factor
            for element in range(row,N):  # Elements from diagonal to right
                A[row,element] = A[row,element] - d * A[col,element]
            b[row] = b[row] - d * b[col]

    return A,b
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
  \frametitle{The program: elimination step}
  Employing some of the row operations to create \lstinline|gaussian_eliminate_v1|:
  \begin{columns}[T]
    \column{0.6\textwidth}
    \begin{lstlisting}
for element in range(row,N):
    A[row,element] = A[row,element] - d * A[col,element]
        \end{lstlisting}    
    \column{0.4\textwidth}
    \begin{lstlisting}
A[row,:] = A[row,:] - d * A[col,:]
        \end{lstlisting}
  \end{columns}
  \pause
  \begin{lstlisting}
def gaussian_eliminate_v1(A,b):
    A = np.array(A,dtype=np.float64)
    b = np.array(b,dtype=np.float64)

    assert A.shape[0] == A.shape[1], "Coefficient matrix should be square"

    N = len(b)
    for col in range(N-1):
        for row in range(col+1,N):
            d = A[row,col] / A[col,col]
            A[row,:] = A[row,:] - d * A[col,:]
            b[row] = b[row] - d * b[col]

    return A,b
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Testing}
  Let's try to eliminate our linear system! If you create/downloaded our file \lstinline|gaussjordan.py|, you can access the functions by importing them. The file should be stored where your own code/notebook is:
  \begin{lstlisting}
from gaussjordan import gaussian_eliminate_draft,gaussian_eliminate_v1
import numpy as np

A = np.array([[1, 1, 1], [2, 1, 3], [3, 1, 6]]) 
b = np.array([4, 7, 5]) 

Aprime,bprime = gaussian_eliminate_draft(A,b)
print(Aprime)
print(bprime)
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
  \frametitle{The program: Backsubstitution}
  Now we have elimination working, let's create a back substitution algorithm too. Recall:
  \[
    x_N = \frac{b_N}{A_{NN}} \qquad x_i = \frac{b_i - \sum_{j=i+1}^{N}A_{ij}x_j}{A_{ii}}
 \]
 \begin{columns}[T]
  \column{0.4\textwidth}
  \begin{lstlisting}[basicstyle=\tiny\ttfamily]
def backsubstitution_draft(A, b):
    """Back substitutes an upper triangular matrix to find x in Ax=b"""
    x = np.copy(b)
    N = len(b)

    for row in range(N-1, -1, -1):
        for i in range(row+1, N):
            x[row] = x[row] - A[row, i] * x[i]
        x[row] = x[row] / A[row, row]  
    
    return x
      \end{lstlisting}\pause
  \column{0.6\textwidth}
  \begin{lstlisting}[basicstyle=\tiny\ttfamily]
def backsubstitution_v1(A,b):
    """Back substitutes an upper triangular matrix to find x in Ax=b"""
    x = np.empty_like(b)
    N = len(b)
    
    for row in range(N)[::-1]:
        x[row] = (b[row] - np.sum(A[row,row+1:] * x[row+1:])) / A[row,row]

    return x
      \end{lstlisting}
 \end{columns}
\end{frame}

% \begin{frame}[fragile]
%   \frametitle{The program: Backsubstitution}
%   \begin{lstlisting}
% def backsubstitution_v1(A,b):
%     """Back substitutes an upper triangular matrix to find x in Ax=b"""
%     x = np.empty_like(b)
%     N = len(b)
    
%     for row in range(N)[::-1]:
%         x[row] = (b[row] - np.sum(A[row,row+1:] * x[row+1:])) / A[row,row]

%     return x
%   \end{lstlisting}
%   \[
%      x_N = \frac{b_N}{A_{NN}} \qquad x_i = \frac{b_i - \sum_{j=i+1}^{N}A_{ij}x_j}{A_{ii}}
%   \]
% \end{frame}

\begin{frame}[fragile]
  \frametitle{A full Gauss Elimination solver}
  \begin{itemize}
    \item The functions we just built are distributed via Canvas too
    \item Use \lstinline$help(gaussian_eliminate_v1)$ to find out how it works
    \item Solve the following system of equations:
    \[
    \begin{bmatrix}
      9 & 9 & 5 & 2\\ 
      6 & 7 & 1 & 3\\ 
      6 & 4 & 3 & 5\\
      2 & 6 & 2 & 1
    \end{bmatrix}
    \begin{bmatrix}x_1\\x_2\\x_3\\x_4\end{bmatrix} = 
    \begin{bmatrix}7\\4\\10\\1\end{bmatrix}
  \]
  \item Compare your solution with \lstinline$np.linalg.solve(A,b)$
  \end{itemize}
\end{frame}

\section{Partial Pivoting}
\subsection*{Pivoting}
\againframe<2>{contents_lin2}

\begin{frame}[fragile]
  \frametitle{Partial pivoting}
  \begin{itemize}
    \item Now try to run the algorithm with the following system:
    \[
    \begin{bmatrix}
      0 & 2 & 1\\ 
      3 & 2 & 1 \\ 
      1 & 1 & 1
    \end{bmatrix}
    \begin{bmatrix}x_1\\x_2\\x_3\end{bmatrix} = 
    \begin{bmatrix}4\\3\\10\end{bmatrix}
  \]
  \pause
  \item It does not work! Division by zero, due to $A_{11}=0$.
  \item Solution: Swap rows to move largest element to the diagonal.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Partial pivoting: implementing row swaps}
  \begin{itemize}[<+->]
    \item Find maximum element row below pivot in current column
    \begin{lstlisting}[numbers=none]
index = np.argmax(np.abs(A[col:, col])) + col 
    \end{lstlisting}
    \item Store current row
    \begin{lstlisting}[numbers=none]
temp = A[column,:]
    \end{lstlisting}
    \item Swap pivot row and desired row in \lstinline$A$
    \begin{lstlisting}[numbers=none]
A[column,:] = A[index,:]
A[index,:] = temp
      \end{lstlisting}
    \item Do the same for \lstinline$b$ --- store and swap
    \begin{lstlisting}[numbers=none]
temp = b[column]
b[column] = b[index]
b[index] = temp
      \end{lstlisting}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Adding the partial pivoting rules}
  \begin{lstlisting}[language=Python]
def gaussian_eliminate_partial_pivot(A,b):
    A = np.array(A,dtype=np.float64)
    b = np.array(b,dtype=np.float64)

    assert A.shape[0] == A.shape[1], "Coefficient matrix should be square"

    N = len(b)
    for col in range(N-1):
        index = np.argmax(np.abs(A[col:, col])) + col
        temp = A[col,:]
        A[col,:] = A[index,:]
        A[index,:] = temp

        temp = b[col]
        b[col] = b[index]
        b[index] = temp
        for row in range(col+1,N):
            d = A[row,col] / A[col,col]
            A[row,:] = A[row,:] - d * A[col,:]
            b[row] = b[row] - d * b[col]

    return A,b
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Improve the program by using re-usable functions}
  \begin{lstlisting}[language=Python]
def swap_rows(mat,i1,i2):
    """Swap two rows in a matrix/vector"""
    temp = mat[i1,...].copy()
    mat[i1,...] = mat[i2,...]
    mat[i2,...] = temp
  \end{lstlisting}
  \begin{lstlisting}[language=Python]
def gaussian_eliminate_v2(A,b):
    A = np.array(A,dtype=np.float64)
    b = np.array(b,dtype=np.float64)

    assert A.shape[0] == A.shape[1], "Coefficient matrix should be square"

    N = len(b)
    for col in range(N-1):
        index = np.argmax(np.abs(A[col:, col])) + col
        swap_rows(A,col,index)
        swap_rows(b,col,index)
        for row in range(col+1,N):
            d = A[row,col] / A[col,col]
            A[row,:] = A[row,:] - d * A[col,:]
            b[row] = b[row] - d * b[col]

    return A,b
  \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Alternatives to this program}
  \begin{itemize}
    \item Python can compute the solution to Ax=b with \lstinline|scipy.linalg.solve| or \lstinline|numpy.linalg.solve| solvers (more efficient)
    \item Too many loops. Loops make Python slow.
    \item There are fundamental problems with Gaussian elimination\pause
    \begin{itemize}
      \item You can add a counter to the algorithm to see how many subtraction and multiplication operations it performs for a given size of matrix A.
      \item The number of operations to perform Gaussian elimination is $\mathcal{O}(2N^3)$ (where $N$ is the number of equations) 
      \item Exercise: verify this for our script \pause
      \item LU decomposition takes $\mathcal{O}(2N^3/3)$ flops, 3 times less!
      \item Forward and backward substitution each take $\mathcal{O}(N^2)$
flops (both cases) 
    \end{itemize}
  \end{itemize}
\end{frame}

\section{LU decomposition}
\subsection*{LU}
\againframe<2>{contents_lin2}

\begin{frame}[fragile]
  \frametitle{LU Decomposition}
  Suppose we want to solve the previous set of equations, but with several right hand sides:
    \[ 
    \begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
A_{21} & A_{22} & A_{23}\\ 
A_{31} & A_{32} & A_{33}
\end{bmatrix}
\begin{bmatrix}
\vdots & \vdots & \vdots \\
x_1 & x_2 & x_3 \\
\vdots & \vdots & \vdots
\end{bmatrix} = 
\begin{bmatrix}
\vdots & \vdots & \vdots \\
b_1 & b_2 & b_3 \\
\vdots & \vdots & \vdots
\end{bmatrix}
\]\pause
Factor the matrix A into two matrices, L and U, such that $A=LU$:
\[ 
    \begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
A_{21} & A_{22} & A_{23}\\ 
A_{31} & A_{32} & A_{33}
\end{bmatrix} = 
\begin{bmatrix}
1 & 0 & 0 \\
\times & 1 & 0 \\
\times & \times & 1
\end{bmatrix}
\begin{bmatrix}
\times & \times & \times \\
0 & \times & \times \\
0 & 0 & \times
\end{bmatrix}
\]
Now we can solve for each right hand side, using only a forward
followed by a backward substitution!
\end{frame}

\begin{frame}[fragile]
  \frametitle{Substitutions}
  \begin{itemize}
    \item Define a lower and upper matrix $L$ and $U$ so that $A = LU$
    \item Therefore $LUx = b$
    \item Define a new vector $y = Ux$ so that $Ly = b$
    \item Solve for $y$, use $L$ and forward substitution
    \item Then we have $y$, solve for $x$, use $Ux = y$
    \item Solve for $x$, use $U$ and backward substitution
    \item But how to get L and U?
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Decomposing the matrix (1)}
  When we eliminate the element $A_{21}$ we can keep multiplying by a matrix that undoes this row operations, so that the product remains equal to $A$.
\[ 
\begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
A_{21} & A_{22} & A_{23}\\ 
A_{31} & A_{32} & A_{33}
\end{bmatrix} = 
\begin{bmatrix}
1 & 0 & 0 \\
d_{21}& 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
\begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
0 & A_{22}-d_{21}A_{12} & A_{23}-d_{21}A_{13}\\ 
A_{31} & A_{32} & A_{33}
\end{bmatrix}
\]
\end{frame}

\begin{frame}[fragile]
  \frametitle{Decomposing the matrix (2)}
  When we eliminate the element $A_{31}$ we can keep multiplying by a matrix that undoes this row operations, so that the product remains equal to $A$.
\[ 
A = 
\begin{bmatrix}
1 & 0 & 0 \\
d_{21}& 1 & 0 \\
d_{31} & 0 & 1
\end{bmatrix}
\begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
0 & A'_{22}=A_{22}-d_{21}A_{12} & A'_{23} = A_{23}-d_{21}A_{13}\\ 
0 & A'_{32} = A_{32}-d_{31}A_{12} & A'_{33} = A_{33}-d_{31}A_{21}
\end{bmatrix}
\]
\end{frame}

\begin{frame}[fragile]
  \frametitle{Decomposing the matrix (3)}
  When we eliminate the element $A_{32}$ we can keep multiplying by a matrix that undoes this row operations, so that the product remains equal to $A$.
\[ 
\begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
A_{21} & A_{22} & A_{23}\\ 
A_{31} & A_{32} & A_{33}
\end{bmatrix} = 
\begin{bmatrix}
1 & 0 & 0 \\
d_{21}& 1 & 0 \\
d_{31} & d_{32} & 1
\end{bmatrix}
\begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
0 & A'_{22} & A'_{23} \\ 
0 & 0  & A''_{33} = A'_{33}-d_{32}A'_{23}
\end{bmatrix}
\]\pause
We now have a lower matrix $L$ and an upper matrix $U$. This finishes the LU decomposition! 
\end{frame}

\subsection*{Pivoting in LU decomposition}
{\nologo
\begin{frame}[fragile]
\frametitle{Pivoting during decomposition}
Suppose we have arrived at the situation below, where $A'_{32}>A'_{22}$:
\vfill
\[ 
\begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
A_{21} & A_{22} & A_{23}\\ 
A_{31} & A_{32} & A_{33}
\end{bmatrix} = 
\begin{bmatrix}
1 & 0 & 0 \\
d_{21}& 1 & 0 \\
d_{31} & 0 & 1
\end{bmatrix}
\begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
0 & \tikzmarkin[mat=style tueturq]{n1} A'_{22} & A'_{23} \\ 
0 & A'_{32}\tikzmarkend{n1} & A'_{33} 
\end{bmatrix}
\]
\vfill 
\pause
Exchange rows 2 and 3 to get the largest value on the main diagonal. Use a permutation matrix to store the swapped rows:
\vfill
\pause
\[ 
\begin{bmatrix}
\tikzmarkin[txt=style tueturq]{n2} 1 & 0 & 0 \\
0& 0 & 1 \\
0 & 1 & 0 \tikzmarkend{n2}
\end{bmatrix}
\begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
A_{21} & A_{22} & A_{23}\\ 
A_{31} & A_{32} & A_{33}
\end{bmatrix} = 
\begin{bmatrix}
1 & 0 & 0 \\
\tikzmarkin[txt=style tueorange]{n3} d_{31}& 0 & 1 \tikzmarkend{n3}\\
\tikzmarkin[txt=style tueorange]{n4} d_{21} & 1 & 0 \tikzmarkend{n4}
\end{bmatrix}
\begin{bmatrix}
A_{11} & A_{12} & A_{13}\\ 
\tikzmarkin[txt=style tueorange]{n5}0 & A'_{32} & A'_{33} \tikzmarkend{n5}\\ 
\tikzmarkin[txt=style tueorange]{n6}0 & A'_{22} & A'_{23} \tikzmarkend{n6} 
\end{bmatrix}
\]
\pause
Multiplying with a permutation matrix will swap the rows of a matrix. The permutation matrix is just an identity matrix, whose rows
have been interchanged.
\end{frame}
}
% 
% \begin{frame}[fragile]
% \frametitle{Pivoting during decomposition}
% Multiplying with a permutation matrix will swap the rows of a matrix. The permutation matrix is just an identity matrix, whose rows
% have been interchanged.
% \vfill
% \[ 
% \begin{bmatrix}
% 1 & 0 & 0 \\
% 0& 0 & 1 \\
% 0 & 1 & 0
% \end{bmatrix}
% \begin{bmatrix}
% A_{11} & A_{12} & A_{13}\\ 
% A_{21} & A_{22} & A_{23}\\ 
% A_{31} & A_{32} & A_{33}
% \end{bmatrix} = 
% \begin{bmatrix}
% 1 & 0 & 0 \\
% d_{31}& 0 & 1 \\
% d_{21} & 1 & 0
% \end{bmatrix}
% \begin{bmatrix}
% A_{11} & A_{12} & A_{13}\\ 
% 0 & A'_{32} & A'_{33} \\ 
% 0 & A'_{22} & A'_{23} 
% \end{bmatrix}
% \]
% \end{frame}

\begin{frame}[fragile]
  \frametitle{Recipe for LU decomposition}
   When decomposing matrix $A$ into $A=LU$, it may be beneficial to swap rows to get the largest values on the diagonal of $U$ (pivoting). A permutation matrix $P$ is used to store row swapping such that:
   \[
    PA = LU
   \]
  \begin{itemize}
    \item Write down a permutation matrix and the linear system
    \item Promote the largest value in the column diagonal
    \item Eliminate all elements below diagonal
    \item Move on to the next column and move largest elements to diagonal
    \item Eliminate elements below diagonal
    \item Repeat 5 and 6
    \item Write down L,U and P
  \end{itemize}
\end{frame}

\subsection*{LU decomposition with pivoting-example}
\begin{frame}[fragile]
  \frametitle{LU decomposition example (1)}
  Write down a permutation matrix, which starts as the identity matrix, and the linear system:
  \begin{align*}
    PA &= LU \\
    \begin{bmatrix}
      1 & 0 & 0\\
      0 & 1 & 0\\
      0 & 0 & 1
    \end{bmatrix} 
    \begin{bmatrix}
      0 & 1 & 1\\
      2 & 1 & 1\\
      1 & 2 & 0
      \end{bmatrix}&= 
      \begin{bmatrix}
      1 & 0 & 0\\
      0 & 1 & 0\\
      0 & 0 & 1
      \end{bmatrix}
      \begin{bmatrix}
      0 & 1 & 1\\
      2 & 1 & 1\\
      1 & 2 & 0
      \end{bmatrix}
  \end{align*}
  \pause
  Promote the largest value into the diagonal of column 1 --- swap row 1 and 2:
    \[
      \begin{bmatrix}
	\tikzmarkin[txt=style yellow]{am1} 0 & 1 & 0\\
	1 & 0 & 0 \tikzmarkend{am1}\\
	0 & 0 & 1
      \end{bmatrix} 
      \begin{bmatrix}
	0 & 1 & 1\\
	2 & 1 & 1\\
	1 & 2 & 0
      \end{bmatrix}= 
      \begin{bmatrix}
	1 & 0 & 0\\
	0 & 1 & 0\\
	0 & 0 & 1
      \end{bmatrix}
      \begin{bmatrix}
	\tikzmarkin[txt=style yellow]{am2}2 & 1 & 0\\
	0 & 1 & 1 \tikzmarkend{am2}\\
	1 & 2 & 0
      \end{bmatrix}
    \]
\end{frame}
% 
\begin{frame}[fragile]
  \frametitle{LU decomposition example (2)}
  Eliminate all \tikzmarkin[txt=style tueorange]{lu1}elements below the diagonal\tikzmarkend{lu1} --- row 2 already contains a zero in column 1, row 3 = row 3 - 0.5 row 1. Record the \tikzmarkin[txt=style tuesteel]{lu2}multiplier 0.5\tikzmarkend{lu2} in $L$:
  \[
    \begin{bmatrix}
      0 & 1 & 0\\
      1 & 0 & 0\\
      0 & 0 & 1
    \end{bmatrix} 
    \begin{bmatrix}
      0 & 1 & 1\\
      2 & 1 & 1\\
      1 & 2 & 0
      \end{bmatrix}= 
      \begin{bmatrix}
      1 & 0 & 0\\
      0 & 1 & 0\\
      \tikzmarkin[txt=style tuesteel]{lu3}0.5\tikzmarkend{lu3} & 0 & 1
      \end{bmatrix}
      \begin{bmatrix}
      2 & 1 & 1\\
      \tikzmarkin[txt=style tueorange]{lu4}0 & 1 & 1\\
      0\tikzmarkend{lu4} & 1.5 & -0.5
      \end{bmatrix}
  \]
  \pause
  Elimination of column 1 is done. Now step to the next column, and move the largest value below/on the diagonal to the diagonal (\tikzmarkin[txt=style yellow]{lu8}swap rows 2 and 3\tikzmarkend{lu8}). Adjust $P$ and the \tikzmarkin[txt=style tueturq]{lu9}lower triangle of $L$\tikzmarkend{lu9} accordingly:
  \[
    \begin{bmatrix}
      0 & 1 & 0\\
      \tikzmarkin[txt=style yellow]{lu5} 0 & 0 & 1 \\
      1 & 0 & 0\tikzmarkend{lu5}
    \end{bmatrix} 
    \begin{bmatrix}
      0 & 1 & 1\\
      2 & 1 & 0\\
      1 & 2 & 0
      \end{bmatrix}= 
      \begin{bmatrix}
      1 & 0 & 0\\
      \tikzmarkin[draw=none,txt=style tueturq]{lu6}(0.25,-0.15)0.5 & 1 & 0\\
      \tikzmarkin[draw=none,txt=style tueturq]{lu10}0\tikzmarkend{lu6} & 0\tikzmarkend{lu10} & 1
      \end{bmatrix}
      \begin{bmatrix}
      2 & 1 & 1\\
      \tikzmarkin[txt=style yellow]{lu7}(0.4,-0.15) 0 & 1.5 & -0.5 \\
      0 & 1 & 1\tikzmarkend{lu7}
      \end{bmatrix}
  \]
\end{frame}

\begin{frame}[fragile]
  \frametitle{LU decomposition example (3)}
    Eliminate \tikzmarkin[txt=style tueorange]{f3}all elements below the diagonal\tikzmarkend{f3} ---\\
    row 3 = row 3 - $\frac{2}{3}$row 2. Record the multiplier \tikzmarkin[txt=style tueturq]{f1}$\frac{2}{3}$\tikzmarkend{f1} in $L$:
  \[
    \begin{bmatrix}
      0 & 1 & 0\\
      0 & 0 & 1 \\
      1 & 0 & 0
    \end{bmatrix} 
    \begin{bmatrix}
      0 & 1 & 1\\
      2 & 1 & 0\\
      1 & 2 & 0
      \end{bmatrix}= 
      \begin{bmatrix}
      1 & 0 & 0\\
      0.5 & 1 & 0\\
      0 & \tikzmarkin[txt=style tueturq]{f2}\frac{2}{3}\tikzmarkend{f2} & 1
      \end{bmatrix}
      \begin{bmatrix}
      2 & 1 & 1\\
      0 & 1.5 & -0.5 \\
      0 & \tikzmarkin[txt=style tueorange]{f4}0\tikzmarkend{f4} & \frac{4}{3}\\
      \end{bmatrix}
  \]
  \pause
  We have obtained the matrices from $PA=LU$:
  \[
    P = \begin{bmatrix}
      0 & 1 & 0\\
      0 & 0 & 1 \\
      1 & 0 & 0
    \end{bmatrix} \quad
    L=\begin{bmatrix}
      1 & 0 & 0\\
      0.5 & 1 & 0\\
      0 & \frac{2}{3} & 1
      \end{bmatrix} \quad
      U = \begin{bmatrix}
      2 & 1 & 1\\
      0 & 1.5 & -0.5 \\
      0 & 0 & \frac{4}{3}\\
      \end{bmatrix}
  \]
  Proceed with solving for $x$.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Substitutions}
  \vskip-2em
  \begin{align*}
    Ax = b \quad  &\Rightarrow \quad PAx=Pb\equiv d\\
    PA = LU \quad&\Rightarrow \quad LUx = d
  \end{align*}
%   \vskip-1ex
  \begin{itemize}
    \item Define a new vector $y=Ux$
    \begin{itemize}
      \item $Ly=b \quad\Rightarrow\quad Ly = d$
      \item Solve for $y$, forward substitution:
      \begin{align*}
	y_0 &= \frac{d_0}{L_{00}} \\
	y_i &= \frac{d_i - \sum_{j=0}^{i}L_{ij}y_j}{L_{ii}}
      \end{align*}
    \end{itemize}
    \item Then solve $Ux=y$:
    \begin{itemize}
      \item Solve for $x$, backward substitution:
      \begin{align*}
	x_N &= \frac{y_N}{U_{NN}} \\
	x_i &= \frac{y_i - \sum_{j=i+1}^{N}U_{ij}x_j}{U_{ii}}
      \end{align*}
    \end{itemize}      
  \end{itemize}  
\end{frame}

\subsection*{Using LU in Python}
\begin{frame}[fragile]
  \frametitle{How to use the solver in Python}
  \begin{lstlisting}[language=Python]
import numpy as np
from scipy.linalg import lu
from gaussjordan import backsubstitution_v1 as backwardSub
from gaussjordan import forwardsubstitution as forwardSub

# Example usage
A = np.random.rand(5, 5)  # Get random matrix
P, L, U = lu(A)           # Get L, U and P
b = np.random.rand(5)     # Random b vector
d = P @ b                 # Permute b vector
y = forwardSub(L, d)      # Can also do y=L\d
x = backwardSub(U, y)     # Can also do x=U\y
rnorm = np.linalg.norm(A @ x - b)  # Residual
  \end{lstlisting}
  \pause
  \begin{itemize}
     \item Use this as a basis to create a function that takes $A$ and $b$, and returns $x$.
     \item Use the function to check the performance for various matrix sizes and inspect the performance.
  \end{itemize}

\end{frame}
\section{Summary}
\subsection*{Summary}
\againframe<2>{contents_lin2}

\begin{frame}[fragile]
  \frametitle{Summary}
  \begin{itemize}
    \item This lecture covered direct methods using elimination techniques.
    \item Gaussian elimination can be slow ($\mathcal{O}(N^3)$)
    \item Back substitution is often faster ($\mathcal{O}(N^2)$)
    \item LU decomposition means that we don't have to do Gaussian elimination every time (saves time and effort), but the matrix has to stay the same.
    \item Python's libraries have built in routines for solving linear equations and LU decomposition.
    \item Advanced techniques such as (preconditioned) conjugate gradient or biconjugate gradient solvers are also available.
    \item Next part covers iterative approaches
\end{itemize}
\end{frame}
